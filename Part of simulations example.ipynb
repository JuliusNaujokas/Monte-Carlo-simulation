{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98789de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b25e0f7",
   "metadata": {},
   "source": [
    "### Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9200f1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path=\"C:/Users/naujo/Documents/STUDIJOS/Bachelor's Thesis Project/Bitcoin Historical Data/btcusd_1-min_data.csv\"\n",
    "\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebe1497",
   "metadata": {},
   "source": [
    "### Cutting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "686f039a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_ts=\t1514764800\n",
    "df=df.loc[df['Timestamp'] >= cut_ts].reset_index(drop=True)\n",
    "\n",
    "df['Datetime'] = pd.to_datetime(df['Timestamp'], unit='s', utc=True)\n",
    "df = df.set_index('Datetime')\n",
    "\n",
    "daily_close = df['Close'].resample('1D').last().dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b63103f",
   "metadata": {},
   "source": [
    "### Define indicator functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7cb63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rsi(series: pd.Series, period: int = 14):\n",
    "    delta = series.diff()\n",
    "    up    = delta.clip(lower=0)\n",
    "    down  = -delta.clip(upper=0)\n",
    "\n",
    "    roll_up   = up.rolling(period).mean()\n",
    "    roll_down = down.rolling(period).mean()\n",
    "    rs = roll_up / roll_down\n",
    "    return 100 - (100 / (1 + rs))\n",
    "\n",
    "def ema(series: pd.Series, span: int):\n",
    "    return series.ewm(span=span, adjust=False).mean()\n",
    "\n",
    "def ew_corr(x: pd.Series, y: pd.Series, span: int = 7):\n",
    "    return x.ewm(span=span, adjust=False).corr(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d63625",
   "metadata": {},
   "source": [
    "### Log Returns and EWC of Log Returns and Volume, 7-day and 14-day EMA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58aaf736",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Log_Returns']=np.log(df['Close']/df['Close'].shift(1))\n",
    "\n",
    "daily = (df.resample('1D').agg({'Close': 'last','Volume': 'sum'}).dropna())\n",
    "\n",
    "daily['RSI14']=rsi(daily['Close'], 14)\n",
    "\n",
    "daily['Log_Returns'] = np.log(daily['Close'] / daily['Close'].shift(1))\n",
    "\n",
    "daily['Log_Vol_Diff']=np.log(daily['Volume'] / daily['Volume'].shift(1))\n",
    "\n",
    "daily['EW_Corr7'] = (daily['Log_Returns'].ewm(span=7, adjust=False).corr(daily['Log_Vol_Diff']))\n",
    "\n",
    "daily['EMA_7']  = daily['Close'].ewm(span=7,  adjust=False).mean()\n",
    "daily['EMA_14'] = daily['Close'].ewm(span=14, adjust=False).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90da5ad",
   "metadata": {},
   "source": [
    "### Defining datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbf8db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = 'Log_Returns'\n",
    "\n",
    "lookback = 14\n",
    "\n",
    "data = daily.dropna().copy()\n",
    "\n",
    "cols=[]\n",
    "for i in range(lookback, 0, -1):\n",
    "    col = f'{target_col}_t-{i}'\n",
    "    data[col] = data[target_col].shift(i)\n",
    "    cols.append(col)\n",
    "\n",
    "data['Log_Vol_Diff'] = data['Log_Vol_Diff']\n",
    "supervised = data.dropna()\n",
    "\n",
    "X = supervised[cols + ['EMA_7', 'EMA_14', 'EW_Corr7', 'Log_Vol_Diff', 'RSI14']].values\n",
    "y = supervised[target_col].values\n",
    "dates = supervised.index "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aada75c2",
   "metadata": {},
   "source": [
    "### Creating training and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67ba8e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (2634, 19),  Test shape: (31, 19)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rewind = 31\n",
    "\n",
    "\n",
    "split_idx   = len(X) - rewind\n",
    "X_train, X_test       = X[:split_idx],  X[split_idx:]\n",
    "y_train, y_test       = y[:split_idx],  y[split_idx:]\n",
    "dates_train, dates_test = dates[:split_idx], dates[split_idx:]\n",
    "\n",
    "print(f\"Train shape: {X_train.shape},  Test shape: {X_test.shape}\")\n",
    "assert len(X_test) == rewind, \"Hold-out length doesn’t match 'rewind'!\"\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler_X = StandardScaler().fit(X_train)\n",
    "scaler_y = StandardScaler().fit(y_train.reshape(-1, 1))\n",
    "\n",
    "X_train_s = scaler_X.transform(X_train)\n",
    "X_test_s  = scaler_X.transform(X_test)\n",
    "y_train_s = scaler_y.transform(y_train.reshape(-1, 1)).ravel()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331e8ede",
   "metadata": {},
   "source": [
    "### Model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76350707",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\naujo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 1.0841 - val_loss: 0.5677\n",
      "Epoch 2/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8429 - val_loss: 0.4322\n",
      "Epoch 3/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6592 - val_loss: 0.3324\n",
      "Epoch 4/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5507 - val_loss: 0.3231\n",
      "Epoch 5/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5524 - val_loss: 0.2993\n",
      "Epoch 6/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4838 - val_loss: 0.2909\n",
      "Epoch 7/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4697 - val_loss: 0.3030\n",
      "Epoch 8/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4410 - val_loss: 0.2864\n",
      "Epoch 9/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4618 - val_loss: 0.2744\n",
      "Epoch 10/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3850 - val_loss: 0.2621\n",
      "Epoch 11/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4172 - val_loss: 0.2629\n",
      "Epoch 12/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4151 - val_loss: 0.2836\n",
      "Epoch 13/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3510 - val_loss: 0.2722\n",
      "Epoch 14/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3706 - val_loss: 0.2736\n",
      "Epoch 15/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3131 - val_loss: 0.2591\n",
      "Epoch 16/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2988 - val_loss: 0.2657\n",
      "Epoch 17/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2815 - val_loss: 0.2624\n",
      "Epoch 18/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2813 - val_loss: 0.2654\n",
      "Epoch 19/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2754 - val_loss: 0.3165\n",
      "Epoch 20/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2694 - val_loss: 0.2528\n",
      "Epoch 21/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2350 - val_loss: 0.2639\n",
      "Epoch 22/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2491 - val_loss: 0.2338\n",
      "Epoch 23/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2193 - val_loss: 0.2528\n",
      "Epoch 24/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2339 - val_loss: 0.2466\n",
      "Epoch 25/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2216 - val_loss: 0.2619\n",
      "Epoch 26/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2513 - val_loss: 0.2442\n",
      "Epoch 27/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1958 - val_loss: 0.2527\n",
      "Epoch 28/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2017 - val_loss: 0.2199\n",
      "Epoch 29/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1785 - val_loss: 0.2491\n",
      "Epoch 30/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1844 - val_loss: 0.2281\n",
      "Epoch 31/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1733 - val_loss: 0.2249\n",
      "Epoch 32/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1681 - val_loss: 0.2197\n",
      "Epoch 33/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1687 - val_loss: 0.2226\n",
      "Epoch 34/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1610 - val_loss: 0.2168\n",
      "Epoch 35/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1479 - val_loss: 0.2306\n",
      "Epoch 36/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1512 - val_loss: 0.2150\n",
      "Epoch 37/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1482 - val_loss: 0.2313\n",
      "Epoch 38/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1394 - val_loss: 0.2322\n",
      "Epoch 39/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1361 - val_loss: 0.2689\n",
      "Epoch 40/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1368 - val_loss: 0.2132\n",
      "Epoch 41/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1435 - val_loss: 0.2230\n",
      "Epoch 42/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1380 - val_loss: 0.2155\n",
      "Epoch 43/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1295 - val_loss: 0.2178\n",
      "Epoch 44/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1228 - val_loss: 0.2218\n",
      "Epoch 45/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1191 - val_loss: 0.2176\n",
      "Epoch 46/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1082 - val_loss: 0.2367\n",
      "Epoch 47/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1163 - val_loss: 0.1983\n",
      "Epoch 48/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1610 - val_loss: 0.2149\n",
      "Epoch 49/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1094 - val_loss: 0.2022\n",
      "Epoch 50/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1115 - val_loss: 0.2249\n",
      "Test RMSE: 0.01942\n"
     ]
    }
   ],
   "source": [
    "X_train_lstm = X_train_s.reshape(X_train_s.shape[0], 1, X_train_s.shape[1])\n",
    "X_test_lstm  = X_test_s.reshape (X_test_s.shape[0],  1, X_test_s.shape[1])\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "regressor = Sequential([\n",
    "    LSTM(50, activation='tanh', return_sequences=True, input_shape=(1, 19)),\n",
    "    LSTM(25, activation='tanh', ),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "regressor.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "regressor.fit(X_train_lstm, y_train_s, epochs=50, batch_size=32, validation_split=0.1, verbose=1)\n",
    "\n",
    "pred_s = regressor.predict(X_test_lstm, verbose=0)\n",
    "pred_lstm   = scaler_y.inverse_transform(pred_s).ravel()\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, pred_lstm))\n",
    "print(f\"Test RMSE: {rmse:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785d201a",
   "metadata": {},
   "outputs": [],
   "source": [
    "k        = 30 \n",
    "n_sims   = 1_000\n",
    "rng      = np.random.default_rng(42)\n",
    "\n",
    "rewind=rewind\n",
    "last_obs   = supervised.iloc[-rewind].copy()\n",
    "start_px   = daily[\"Close\"].iloc[-rewind]\n",
    "\n",
    "train_pred = scaler_y.inverse_transform(\n",
    "                regressor.predict(X_train_lstm, verbose=0)\n",
    "            ).ravel()\n",
    "residuals  = y_train - train_pred\n",
    "\n",
    "def make_feature_tensor(row_like_series: pd.Series) -> np.ndarray:\n",
    "    feats   = row_like_series[cols +['EMA_7', 'EMA_14', 'Volume', 'Log_Vol_Diff', 'RSI14']].values\n",
    "    X_scaled = scaler_X.transform(feats.reshape(1, -1))\n",
    "    return X_scaled.reshape(1, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5f78862",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_log_ret = np.zeros((n_sims, k), dtype=float)\n",
    "\n",
    "for p in range(n_sims):\n",
    "    row = last_obs.copy()\n",
    "    ema7, ema14 = row['EMA_7'], row['EMA_14']\n",
    "\n",
    "    for t in range(k):\n",
    "        mu_t = scaler_y.inverse_transform(\n",
    "                   regressor.predict(make_feature_tensor(row), verbose=0)\n",
    "               ).item()\n",
    "\n",
    "       \n",
    "        eps_t = rng.choice(residuals)\n",
    "        r_t   = mu_t + eps_t\n",
    "        sim_log_ret[p, t] = r_t\n",
    "\n",
    "       \n",
    "        for i in range(lookback, 1, -1):\n",
    "            row[f'{target_col}_t-{i}'] = row[f'{target_col}_t-{i-1}']\n",
    "        row[f'{target_col}_t-1'] = r_t\n",
    "        row[target_col]          = r_t\n",
    "\n",
    "        ema7   = (r_t + ema7*6)  / 7\n",
    "        ema14  = (r_t + ema14*13)/14\n",
    "        row['EMA_7'], row['EMA_14'] = ema7, ema14\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7b7769",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.dates as mdates\n",
    "\n",
    "\n",
    "anchor_dt = daily.index[-rewind] \n",
    "anchor_ix = daily.index.get_loc(anchor_dt)\n",
    "forecast_dates = daily.index[anchor_ix+1 : anchor_ix+1+k]\n",
    "assert len(forecast_dates) == k, \"daily index too short for k!\"\n",
    "\n",
    "price_paths_df = pd.DataFrame(price_paths, columns=forecast_dates)\n",
    "\n",
    "median_path = price_paths_df.median()\n",
    "quantiles = price_paths_df.quantile([0.025, 0.975])\n",
    "p_low = quantiles.loc[0.025]\n",
    "p_high = quantiles.loc[0.975]\n",
    "\n",
    "realised = daily.loc[forecast_dates, \"Close\"]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "\n",
    "ax.plot(price_paths_df.T, color=\"grey\", alpha=0.03)\n",
    "ax.plot(forecast_dates, median_path, lw=2, label=\"median\")\n",
    "ax.fill_between(forecast_dates, p_low, p_high,\n",
    "                alpha=0.22, label=\"95 % CI\")\n",
    "ax.plot(forecast_dates, realised, \"o-\", lw=1.5, label=\"realised\", color='green')\n",
    "\n",
    "\n",
    "ax.set_xlim(forecast_dates[0], forecast_dates[-1])\n",
    "ax.set_title(f\"Monte-Carlo fan: {k} business days after {anchor_dt.date()}\")\n",
    "ax.set_ylabel(\"Price\")\n",
    "ax.legend(frameon=False)\n",
    "ax.grid(True)\n",
    "\n",
    "ax.xaxis.set_major_locator(mdates.DayLocator(interval=5))\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%Y-%m-%d\"))\n",
    "fig.autofmt_xdate()\n",
    "plt.tight_layout(); plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
